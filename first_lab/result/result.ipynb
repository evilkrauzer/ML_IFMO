{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1\n",
    "### 1. Постановка задачи\n",
    "1. На языке Python программно реализовать два метрических алгоритма классификации: Naive Bayes и K Nearest Neighbours\n",
    "2. Сравнить работу реализованных алгоритмов с библиотечными из scikit-learn\n",
    "3. Для тренировки, теста и валидации использовать один из предложенных датасетов (либо найти самостоятельно и внести в таблицу)\n",
    "4. Сформировать краткий отчет (постановка задачи, реализация, эксперимент с данными, полученные характеристики, вывод\n",
    "\n",
    "### 2. Исходные данные\n",
    "**Датасет**: https://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions\n",
    "<br>\n",
    "**Предметная область**: Человеческая активность, различные движения\n",
    "<br>**Список классов**:\n",
    "1. WALKING\n",
    "2. WALKING_UPSTAIRS\n",
    "3. WALKING_DOWNSTAIRS\n",
    "4. SITTING\n",
    "5. STANDING\n",
    "6. LAYING\n",
    "7. STAND_TO_SIT\n",
    "8. SIT_TO_STAND\n",
    "9. SIT_TO_LIE\n",
    "10. LIE_TO_SIT\n",
    "11. STAND_TO_LIE\n",
    "12. LIE_TO_STAND\n",
    "\n",
    "**Количество атрибутов**: 561\n",
    "<br>\n",
    "**Основные атрибуты**: Измерения гироскопа и акселерометра в 3х осях, фильтры их значений\n",
    "<br>\n",
    "**Полный список атрибутов**: Features.txt\n",
    "### 3. Ход работы\n",
    "#### 1. Реализация алгоритма Naive Bayes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    summaries = {}\n",
    "\n",
    "    # обучение классификатора\n",
    "    def fit(self, train_data, train_classes):\n",
    "        # получаем словарь с данными, разделенный по классам\n",
    "        classes_dict = self.separate_by_class(train_data, train_classes)\n",
    "\n",
    "        for class_name, items in classes_dict.items():\n",
    "            # считаем среднее значение и среднеквадратичное отклонение атрибутов для каждого класса входных данных\n",
    "            self.summaries[class_name] = self.summarize(items)\n",
    "\n",
    "    def separate_by_class(self, train_data, train_classes):\n",
    "        classes_dict = {}\n",
    "        for i in range(len(train_data)):\n",
    "            classes_dict.setdefault(train_classes[i], []).append(train_data[i])\n",
    "\n",
    "        return classes_dict\n",
    "\n",
    "    # обобщаем данные\n",
    "    def summarize(self, class_data):\n",
    "        summaries = [(self.mean(attributes), self.stand_dev(attributes)) for attributes in\n",
    "                     zip(*class_data)]\n",
    "        return summaries\n",
    "\n",
    "    # вычисление среднего значения\n",
    "    def mean(self, values):\n",
    "        return sum(values) / float(len(values))\n",
    "\n",
    "    # вычисление дисперсии\n",
    "    def stand_dev(self, values):\n",
    "        var = sum([pow(x - self.mean(values), 2) for x in values]) / float(len(values) - 1)\n",
    "        return math.sqrt(var)\n",
    "\n",
    "    # классификация тестовой выборки\n",
    "    def predict(self, data_x):\n",
    "        predictions = []\n",
    "        for x in data_x:\n",
    "            predictions.append(self.predict_one(self.summaries, x))\n",
    "        return predictions\n",
    "\n",
    "    # классификация одного объекта\n",
    "    def predict_one(self, summaries, x):\n",
    "        probabilities = self.calc_class_probabilities(summaries, x)\n",
    "        best_class = None\n",
    "        max_prob = -1\n",
    "        for class_name, probability in probabilities.items():\n",
    "            if best_class is None or probability > max_prob:\n",
    "                max_prob = probability\n",
    "                best_class = class_name\n",
    "        return best_class\n",
    "\n",
    "    # вычисление вероятности принадлежности объекта к каждому из классов\n",
    "    def calc_class_probabilities(self, summaries, instance_attr):\n",
    "        probabilities = {}\n",
    "        for class_name, class_summaries in summaries.items():\n",
    "            probabilities[class_name] = 1.0\n",
    "            for i in range(len(class_summaries)):\n",
    "                mean, stdev = class_summaries[i]\n",
    "                x = float(instance_attr[i])\n",
    "                probabilities[class_name] *= self.calc_probability(x, mean, stdev)\n",
    "        return probabilities\n",
    "\n",
    "    # вычисление апостериорной вероятности принадлежности объекта к определенному классу\n",
    "    def calc_probability(self, x, mean, stdev):\n",
    "        if stdev == 0:\n",
    "            stdev += 0.000001\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2))))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнение работы реализованного алгоритма с библиотечным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data, file_classes = utils.load_data()\n",
    "data = Data(file_data, file_classes, 1, 0.7)\n",
    "\n",
    "# NB\n",
    "gnb = GaussianNB()\n",
    "nb_clf = gnb.fit(data.train_data, data.train_classes)\n",
    "accuracy = accuracy_score(data.test_classes, gnb.predict(data.test_data))\n",
    "print('Naive Bayes Accuracy: %.8f' % accuracy)\n",
    "\n",
    "# my NB\n",
    "bayes_native = NaiveBayes()\n",
    "bayes_native.fit(data.train_data, data.train_classes)\n",
    "bayes_native_accuracy = accuracy_score(data.test_classes, bayes_native.predict(data.test_data))\n",
    "print('my naive Bayes Accuracy: %.8f' % bayes_native_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes Accuracy**: 0.79613734\n",
    "<br>**my naive Bayes Accuracy**: 0.78969957"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Реализация алгоритма K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors:\n",
    "    def __init__(self, neighbours_size):\n",
    "        self.neighbours_size = neighbours_size\n",
    "\n",
    "    def fit(self, train_x, train_y):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "\n",
    "    # классификация тестовой выборки\n",
    "    def predict(self, data_x):\n",
    "        predictions = []\n",
    "        for x in data_x:\n",
    "            neighbours = self.get_neighbours(x)\n",
    "            predicted_class = self.predict_class(neighbours)\n",
    "            predictions.append(predicted_class)\n",
    "        return predictions\n",
    "\n",
    "    # находим расстояния до всех объектов\n",
    "    def get_neighbours(self, inst):\n",
    "        distances = []\n",
    "        for i in self.train_x:\n",
    "            distances.append(self.get_euclidean_distance(i, inst))\n",
    "        distances = tuple(zip(distances, self.train_y))\n",
    "        sorted_list = sorted(distances)[:self.neighbours_size]\n",
    "\n",
    "        class_name_list = []\n",
    "        for value, class_name in sorted_list:\n",
    "            class_name_list.append(class_name)\n",
    "        return class_name_list\n",
    "\n",
    "    # евклидово расстояние между двумя объектами\n",
    "    def get_euclidean_distance(self, inst1, inst2):\n",
    "        distances = [(i - j) ** 2 for i, j in zip(inst1, inst2)]\n",
    "        return math.sqrt(sum(distances))\n",
    "\n",
    "    # определение самого распространенного класса среди соседей\n",
    "    def predict_class(self, neighbours):\n",
    "        return Counter(neighbours).most_common()[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнение работы реализованного алгоритма с библиотечным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "sklearn_kn_clf = KNeighborsClassifier(10)\n",
    "sklearn_kn_clf.fit(data.train_data, data.train_classes)\n",
    "sklearn_kn_clf_accuracy = accuracy_score(data.test_classes, sklearn_kn_clf.predict(data.test_data))\n",
    "print('knn Accuracy: {:.8%}'.format(sklearn_kn_clf_accuracy))\n",
    "\n",
    "# My KNN\n",
    "my_kn_clf = KNearestNeighbors(10)\n",
    "my_kn_clf.fit(data.train_data, data.train_classes)\n",
    "my_kn_clf_accuracy = accuracy_score(data.test_classes, my_kn_clf.predict(data.test_data))\n",
    "print('my knn Accuracy: {:.8%}'.format(my_kn_clf_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**knn Accuracy**: 90.98712446% <br>\n",
    "**my knn Accuracy**: 92.06008584%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вспомогательные методы\\классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = np.loadtxt('../HAPT Data Set/Train/X_train.txt', delimiter=' ')\n",
    "    classes = np.loadtxt('../HAPT Data Set/Train/y_train.txt')\n",
    "    return data, classes\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, data, classes, size, train_size, attributes_count = 561):\n",
    "        size = int(data.shape[0] * size)\n",
    "        self.data = data[0:size, :attributes_count]\n",
    "        self.classes = classes[0:size]\n",
    "        self.train_data, self.test_data, self.train_classes, self.test_classes = train_test_split(self.data, self.classes,\n",
    "                                                                                                  train_size=train_size,\n",
    "                                                                                                  test_size=1 - train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "В ходе лабораторной работы были получены практические навыки работы с метрическими методами машинного обучения на практических примерах с использованием языка программирования python и библиотеки sklearn.\n",
    "<br>\n",
    "<br>\n",
    "Были использованы классификаторы K Nearest Neighbor Classifier и Naive Bayes Classifier из библиотеки sklearn, а также имплиментироваы собственные реализации данных алгоритмов. Библиотечные и реализованные алгоритмы показали примерно одинаковую высокую точность предсказаний.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
